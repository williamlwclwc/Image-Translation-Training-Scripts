Automatically translating one possible representation of a scene into another given sufficient training data 
is one of the popular applications of recent generative models. The work of Isola et al.\cite{pix2pix2016} 
has proved that Generative Adversarial Network(GAN) is an effective end-to-end process for generating images 
with rich details such as photorealistic images from sketches such as edge maps or segmentation maps. 
Following this work, more models have been proposed to improve the results. This report starts with a gentle 
introduction to these topics and discuss the achievements of the existent state-of-the-art models which 
translate segmentation maps into photorealistic images. 
Moreover, I manage to implement two recent high computational resources demanded state-of-the-art models with 
limited computational resources on a smaller dataset. The implementation details and 
results are shown and the advantages and disadvantages of the models are analyzed in this report.



